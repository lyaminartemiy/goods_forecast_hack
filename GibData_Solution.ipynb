{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "429943bd-d0c8-4990-a8e4-e9e92a46818f",
   "metadata": {},
   "source": [
    "## Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "de72281a-331a-4ca6-9751-e75fe8fe3db4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from scipy import stats\n",
    "from tqdm import tqdm, trange\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Under/Over Sampling\n",
    "from imblearn.under_sampling import TomekLinks\n",
    "from imblearn.over_sampling import RandomOverSampler, ADASYN, BorderlineSMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "07624a06-06d1-49f9-b81a-61e66c22baa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Models & Metrics\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import ExtraTreesClassifier, RandomForestClassifier, AdaBoostClassifier, GradientBoostingClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from catboost import CatBoostClassifier\n",
    "\n",
    "from imblearn.ensemble import BalancedBaggingClassifier, EasyEnsembleClassifier\n",
    "from imblearn.ensemble import RUSBoostClassifier, BalancedRandomForestClassifier\n",
    "\n",
    "from sklearn.metrics import roc_auc_score, roc_curve, f1_score, classification_report, precision_score, recall_score, f1_score\n",
    "from sklearn.utils.class_weight import compute_class_weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e2c282fc-7043-4819-837e-f69a182e8937",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Настройки\n",
    "# Убираем ограничение отображемых колонок\n",
    "pd.options.display.max_columns = None\n",
    "pd.options.display.max_rows = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e74a4d4f-75e8-4b3e-ae00-a15d4c99929e",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7f4ea71e-4855-416f-97b6-286f3599097a",
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = \"data/\"\n",
    "\n",
    "features_filename = PATH + \"Features.csv\"\n",
    "agg_features_filename = PATH + \"features_22.csv\"\n",
    "src_features_filename = PATH + \"last_price_quant.csv\"\n",
    "lag_features_filename = PATH + \"Features_lag.csv\"\n",
    "std_features_filename = PATH + \"lag_1_5_mean_std_var.csv\"\n",
    "stocks_features_filename = PATH + \"stocks_features.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "200efe7e-16cf-4132-8e66-6779264166b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 4.08 s\n",
      "Wall time: 4.09 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "features = pd.read_csv(features_filename)\n",
    "\n",
    "agg_features = pd.read_csv(agg_features_filename)\n",
    "agg_features = agg_features.drop(columns=['Unnamed: 0', 'IsCorrect'])\n",
    "\n",
    "src_features = pd.read_csv(src_features_filename)\n",
    "src_features = src_features.drop(columns=['Unnamed: 0', 'Datetime'])\n",
    "\n",
    "std_features = pd.read_csv(std_features_filename)\n",
    "std_features = std_features.drop(columns=['Unnamed: 0', 'IsCorrect'])\n",
    "\n",
    "stocks_features = pd.read_csv(stocks_features_filename)\n",
    "stocks_features = stocks_features.drop(columns=['Unnamed: 0'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5ea19098-7228-429f-8c73-86ed201ea3cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = features.merge(agg_features, how='left', on=['LocationId', 'ProductId', 'ValidationDateTime'])\n",
    "features = features.merge(src_features, how='left', on=['LocationId', 'ProductId', 'ValidationDateTime'])\n",
    "features = features.merge(std_features, how='left', on=['LocationId', 'ProductId', 'ValidationDateTime'])\n",
    "features = features.merge(stocks_features, how='left', on=['LocationId', 'ProductId', 'ValidationDateTime'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c876296-0364-4909-8e6a-3b0b02d27d59",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Удаляем вероятности, поскольку решаем задачу \"Направление №1\"\n",
    "features = features.drop(columns=['Probability'])\n",
    "features = features.drop(columns=['Column53', 'Column54', 'Column55', 'Column56'])\n",
    "\n",
    "# Сортируем данные по времени\n",
    "features = features.sort_values(by='ValidationDateTime')\n",
    "features['ValidationDateTime'] = pd.to_datetime(features['ValidationDateTime'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f19ff747-d0a7-404b-a74f-93157b20c3fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Разделяем выборку на тренировочную и обучающую\n",
    "filter_na_target = features['IsCorrect'].isna()\n",
    "df_train = features[~filter_na_target]\n",
    "df_test = features[filter_na_target]\n",
    "\n",
    "# Приводим таргет к целочисленному типу\n",
    "df_train['IsCorrect'] = df_train['IsCorrect'].astype(np.uint8)\n",
    "\n",
    "# Разбиваем данные на обучающие и валидацию для чек-поинта\n",
    "train_checkpoint = df_train.query('ValidationDateTime >= \"2023-07-15\"')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7645d20-5b39-4732-b47f-c9be2e164acc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = df_train.query(\"(ValidationDateTime >= '2023-07-09') & (ValidationDateTime < '2023-07-15')\")\n",
    "df_train = pd.concat([df_train, train_checkpoint])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a58b5a55-bd54-4eec-bf17-0b761367c2fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Смотрим сколько признаков имеют NaN для большинства объектов\n",
    "# Отдельно по классам и если для обоих классов эти признаки не значимы, тогда удаляем признаки\n",
    "threshold_drop = 0.9\n",
    "nan_df_cls1 = df_train[df_train[\"IsCorrect\"] == 1].isna().sum()\n",
    "nan_df_cls0 = df_train[df_train[\"IsCorrect\"] == 0].isna().sum()\n",
    "count_cls1 = len(df_train[df_train[\"IsCorrect\"] == 1] )\n",
    "count_cls0 = len(df_train[df_train[\"IsCorrect\"] == 0] )\n",
    "drop_col_cls1 =  nan_df_cls1[nan_df_cls1 > count_cls1*threshold_drop]\n",
    "drop_col_cls0 =  nan_df_cls0[nan_df_cls0 > count_cls0*threshold_drop]\n",
    "drop_columns = set(drop_col_cls1.index) & set(drop_col_cls0.index)\n",
    "\n",
    "# Исключаем признаки с большим кол-ом пропусков\n",
    "df_train = df_train.drop(columns=drop_columns, errors='ignore')\n",
    "df_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01c41581-d5fd-4b9f-92a8-a5b855e62068",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loc_id = set(df_train['LocationId'].unique())\n",
    "test_loc_id = set(df_test['LocationId'].unique())\n",
    "df_train = df_train[df_train['LocationId'].apply(lambda x: x in test_loc_id)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "976c1bfe-5688-42ac-8055-bdf25a9094b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_prod_id = set(df_train['ProductId'].unique())\n",
    "test_prod_id = set(df_test['ProductId'].unique())\n",
    "df_train = df_train[df_train['ProductId'].apply(lambda x: x in test_prod_id)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13a37c92-ed7b-49c9-92f9-58eb5d22b526",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_column = 'IsCorrect'\n",
    "report_date_column = 'ValidationDateTime'\n",
    "id_client_columns = [\"LocationId\", \"ProductId\"]\n",
    "feature_columns = list(set(df_train.columns) - set([report_date_column]) - set([target_column]) - set(id_client_columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "667f46b4-7878-4312-9c44-827e4e3d38fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Поиск константных признаков\n",
    "constant_features = []\n",
    "# Если везде одно значение  - это константа\n",
    "for column in feature_columns:\n",
    "    if len(df_train[column].value_counts()) == 1:\n",
    "        constant_features.append(column)\n",
    "df_train = df_train.drop(columns=constant_features, errors='ignore')\n",
    "feature_columns = list(set(feature_columns) - set(constant_features))\n",
    "df_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae3d3622-0a15-4685-bb72-49e674bc4e83",
   "metadata": {},
   "source": [
    "## Train and Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69f2f1c8-b583-42fb-8bdf-8a8b5653d8cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = df_train[feature_columns]\n",
    "y_train = df_train[target_column]\n",
    "\n",
    "X_val = df_test[feature_columns]\n",
    "# y_val = df_train[target_column]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb550da3-f389-45f3-aefc-792b3e2c32b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Вывод графика ROC-AUC\n",
    "def plot_roc_auc(y_true, y_pred):\n",
    "    fpr, tpr, _ = roc_curve(y_true=y_true, y_score=y_pred)\n",
    "    roc_auc = roc_auc_score(y_true=y_true, y_score=y_pred)\n",
    "\n",
    "    plt.figure(figsize=(10, 3))\n",
    "    plt.plot(fpr, tpr, color='darkorange',\n",
    "             lw=2, label='ROC curve (area = %0.4f)' % roc_auc, alpha=0.5)\n",
    "\n",
    "    plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--', alpha=0.5)\n",
    "\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.xticks(fontsize=12)\n",
    "    plt.yticks(fontsize=12)\n",
    "    plt.grid(True)\n",
    "    plt.xlabel('False Positive Rate', fontsize=12)\n",
    "    plt.ylabel('True Positive Rate', fontsize=12)\n",
    "    plt.title('Receiver operating characteristic', fontsize=16)\n",
    "    plt.legend(loc=\"lower right\", fontsize=12)\n",
    "    plt.show()\n",
    "    return roc_auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "339ba120-a505-4a84-87f4-4eb84345b80c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Вывод графика feature importance\n",
    "def plot_feature_importance(importance, names, model_name=\"\", top_n=-1, skip_columns=[]):\n",
    "    \"\"\"Функция вывода feature importance\n",
    "        :importance - массив важности фичей, полученный от модели\n",
    "        :names - массив названий фичей\n",
    "        :model_name - название модели\n",
    "        :top_n - кол-во выводимых фичей\n",
    "        :skip_columns: какие фичи пропустить, такое может понадобиться чтобы временно убрать \n",
    "                        из отображаемых горячие фичи, и изучить менее сильные\n",
    "        :return - fi_df - feature importance датафрейм\n",
    "    \"\"\"\n",
    "    feature_importance = np.array(importance)\n",
    "    feature_names = np.array(names)\n",
    "    \n",
    "    data={'feature_names':feature_names,'feature_importance':feature_importance}\n",
    "    fi_df = pd.DataFrame(data)\n",
    "    fi_df = fi_df[~fi_df['feature_names'].isin(skip_columns)]\n",
    "    fi_df.sort_values(by=['feature_importance'], ascending=False,inplace=True)\n",
    "    \n",
    "    plt.figure(figsize=(10,8))\n",
    "    sns.barplot(x=fi_df['feature_importance'][:top_n], y=fi_df['feature_names'][:top_n])\n",
    "    if top_n != -1:\n",
    "        plt.title(f\"{model_name} FEATURE IMPORTANCE (Top: {top_n})\")\n",
    "    else:\n",
    "        plt.title(f\"{model_name} FEATURE IMPORTANCE\")\n",
    "    plt.xlabel('FEATURE IMPORTANCE')\n",
    "    plt.ylabel('FEATURE NAMES')\n",
    "    return fi_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46ffa05b-35a2-4232-9046-8141964194c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def metrics_classifie(y_test, X_test, y_pred,model, name='model'):\n",
    "    precision = precision_score(y_test, y_pred)\n",
    "    recall = recall_score(y_test, y_pred)\n",
    "    f1 = f1_score(y_test, y_pred)\n",
    "    print(f'{name} - Precision: {precision:.2f} | Recall: {recall:.2} | F1-score: {f1:.2} | ROCAUC: {roc_auc_score(y_true=y_test, y_score=model.predict_proba(X_test)[:,1])}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19167d3f-fec0-496b-9aee-369b3cb84280",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Расчет дисбалнса классов\n",
    "classes = np.unique(y_train)\n",
    "weights = compute_class_weight(class_weight='balanced', classes=classes, y=y_train)\n",
    "class_weights = dict(zip(classes, weights))\n",
    "class_weights"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abf34bc1-73a9-4d8c-aa81-22f2b4eee453",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fd5bb7d-f415-4b09-9392-379199c2be4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CatBoostClassifier(\n",
    "    iterations=200,\n",
    "    max_depth=4,\n",
    "    l2_leaf_reg=7,\n",
    "    colsample_bylevel=0.098,\n",
    "    subsample=0.71,\n",
    "    min_data_in_leaf=243,\n",
    "    max_bin=150,\n",
    "    random_strength=1,\n",
    "    eval_metric=\"AUC\",\n",
    "    early_stopping_rounds=100, \n",
    "    class_weights=class_weights, \n",
    "    random_state=53\n",
    ")\n",
    "model.fit(X_train, y_train, plot=True, verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1187ea60-28c8-44e1-85b0-779729b6e9b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Построение важности признаков\n",
    "dfi = plot_feature_importance(model.get_feature_importance(), X_val.columns, top_n=30)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f00375b-3402-4d59-a676-f824b4b57cd5",
   "metadata": {},
   "source": [
    "## Making Submit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe4bead4-7055-4cb6-96fc-f82b61839b98",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_proba = model.predict_proba(X_val)[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d3b3a50-f9af-41e5-8be2-da12f6c8b8a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "submit = df_test[['LocationId', 'ProductId', 'ValidationDateTime']]\n",
    "submit['CalculatedProbability'] = y_pred_proba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6a4ae7f-d065-4562-b7c8-6c43d3bdc0a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "submit.to_csv(\"GibData_3.csv\", index=False, sep=';')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
